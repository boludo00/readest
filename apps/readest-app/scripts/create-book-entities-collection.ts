#!/usr/bin/env npx tsx
/**
 * Creates the 'book_entities' collection in Appwrite database for X-Ray cloud sync.
 *
 * Usage:
 *   npx tsx scripts/create-book-entities-collection.ts
 *
 * Requires these env vars (from .env.tauri):
 *   NEXT_PUBLIC_APPWRITE_ENDPOINT
 *   NEXT_PUBLIC_APPWRITE_PROJECT_ID
 *   APPWRITE_API_KEY
 *   APPWRITE_DATABASE_ID
 */

import { readFileSync } from 'fs';
import { resolve } from 'path';
import { Client, Databases, IndexType } from 'node-appwrite';

// Load env vars from .env.tauri
function loadEnvFile(filePath: string) {
  try {
    const content = readFileSync(filePath, 'utf-8');
    for (const line of content.split('\n')) {
      const trimmed = line.trim();
      if (!trimmed || trimmed.startsWith('#')) continue;
      const eqIdx = trimmed.indexOf('=');
      if (eqIdx === -1) continue;
      const key = trimmed.slice(0, eqIdx).trim();
      const value = trimmed.slice(eqIdx + 1).trim();
      if (!process.env[key]) {
        process.env[key] = value;
      }
    }
  } catch {
    // file doesn't exist
  }
}

loadEnvFile(resolve(__dirname, '..', '.env.tauri'));
loadEnvFile(resolve(__dirname, '..', '.env.local'));

const endpoint = process.env['NEXT_PUBLIC_APPWRITE_ENDPOINT'] || '';
const projectId = process.env['NEXT_PUBLIC_APPWRITE_PROJECT_ID'] || '';
const apiKey = process.env['APPWRITE_API_KEY'] || '';
const databaseId = process.env['APPWRITE_DATABASE_ID'] || '';

if (!endpoint || !projectId || !apiKey || !databaseId) {
  console.error('Missing required env vars in .env.tauri:');
  console.error('  NEXT_PUBLIC_APPWRITE_ENDPOINT');
  console.error('  NEXT_PUBLIC_APPWRITE_PROJECT_ID');
  console.error('  APPWRITE_API_KEY');
  console.error('  APPWRITE_DATABASE_ID');
  process.exit(1);
}

const client = new Client().setEndpoint(endpoint).setProject(projectId).setKey(apiKey);
const databases = new Databases(client);

async function sleep(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function waitForAttribute(collectionId: string, attrKey: string, maxWait = 30000) {
  const start = Date.now();
  while (Date.now() - start < maxWait) {
    try {
      const attr = await databases.getAttribute(databaseId, collectionId, attrKey);
      if (attr.status === 'available') return;
    } catch {
      // attribute may not exist yet
    }
    await sleep(1000);
  }
  console.warn(`  Warning: attribute '${attrKey}' did not become available within ${maxWait}ms`);
}

async function main() {
  console.log(`\nðŸš€ Creating 'book_entities' collection in Appwrite...`);
  console.log(`   Endpoint: ${endpoint}`);
  console.log(`   Project: ${projectId}`);
  console.log(`   Database: ${databaseId}\n`);

  const collectionId = 'book_entities';

  // Check if collection already exists
  try {
    await databases.getCollection(databaseId, collectionId);
    console.log(`âœ… Collection '${collectionId}' already exists!`);
    process.exit(0);
  } catch {
    console.log(`ðŸ“ Collection '${collectionId}' doesn't exist, creating...`);
  }

  // Create collection
  try {
    await databases.createCollection(databaseId, collectionId, 'Book Entities', [
      'create("users")',
      'read("users")',
      'update("users")',
      'delete("users")',
    ]);
    console.log(`âœ… Created collection '${collectionId}'`);
  } catch (error) {
    console.error(`âŒ Failed to create collection:`, error);
    process.exit(1);
  }

  // Wait a bit for collection to be ready
  await sleep(2000);

  // Create attributes
  const attributes = [
    { key: 'user_id', type: 'string', size: 36, required: true },
    { key: 'book_hash', type: 'string', size: 64, required: true },
    { key: 'entities', type: 'string', size: 1000000, required: true }, // 1MB for JSON entities
    { key: 'entity_index', type: 'string', size: 500000, required: true }, // 500KB for JSON index
    { key: 'created_at', type: 'string', size: 30, required: false },
    { key: 'updated_at', type: 'string', size: 30, required: false },
  ];

  console.log(`\nðŸ“‹ Creating ${attributes.length} attributes...`);
  for (const attr of attributes) {
    try {
      await databases.createStringAttribute(
        databaseId,
        collectionId,
        attr.key,
        attr.size,
        attr.required,
      );
      console.log(`  âœ… ${attr.key} (${attr.type}, size=${attr.size}, required=${attr.required})`);
      await waitForAttribute(collectionId, attr.key);
    } catch (error: any) {
      console.error(`  âŒ Failed to create attribute '${attr.key}':`, error.message);
    }
  }

  // Create indexes
  const indexes = [
    { key: 'idx_user_id', type: IndexType.Key, attributes: ['user_id'] },
    { key: 'idx_user_book_hash', type: IndexType.Unique, attributes: ['user_id', 'book_hash'] },
  ];

  console.log(`\nðŸ” Creating ${indexes.length} indexes...`);
  await sleep(2000); // Wait for all attributes to be ready

  for (const index of indexes) {
    try {
      await databases.createIndex(
        databaseId,
        collectionId,
        index.key,
        index.type,
        index.attributes,
      );
      console.log(`  âœ… ${index.key} (${index.type})`);
    } catch (error: any) {
      console.error(`  âŒ Failed to create index '${index.key}':`, error.message);
    }
  }

  console.log(`\nðŸŽ‰ Done! Collection 'book_entities' is ready.`);
  console.log(
    `\nðŸ“ Collection permissions set to: create("users"), read("users"), update("users"), delete("users")`,
  );
  console.log(`   This allows any authenticated user to manage their X-Ray entities.\n`);
}

main().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
